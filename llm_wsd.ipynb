{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from loader import load_instances, load_key\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.wsd import lesk\n",
    "import random\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load instances and key data in another cell\n",
    "data_f = 'multilingual-all-words.en.xml'  \n",
    "key_f = 'wordnet.en.key'\n",
    "\n",
    "dev_instances, test_instances = load_instances(data_f)\n",
    "dev_key, test_key = load_key(key_f)\n",
    "\n",
    "dev_instances = {k:v for (k,v) in dev_instances.items() if k in dev_key}\n",
    "test_instances = {k:v for (k,v) in test_instances.items() if k in test_key}\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_and_lemmatize(word):\n",
    "    # Remove punctuation\n",
    "    word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Lemmatize\n",
    "    return lemmatizer.lemmatize(word)\n",
    "\n",
    "def create_dataframe(instances, key_dict):\n",
    "    data = []\n",
    "    for instance_id, instance in instances.items():\n",
    "        # Decode lemma and context if in byte format\n",
    "        lemma = instance.lemma.decode('utf-8') if isinstance(instance.lemma, bytes) else instance.lemma\n",
    "        context = [word.decode('utf-8') if isinstance(word, bytes) else word for word in instance.context]\n",
    "\n",
    "        # Retrieve the sense key(s) from key_dict, or None if not found\n",
    "        sense_key = key_dict.get(instance_id, [None])\n",
    "        \n",
    "        # Append the processed data\n",
    "        data.append({\n",
    "            'Instance ID': instance_id,             \n",
    "            'Lemma': lemma,                         \n",
    "            'Original Context': context,\n",
    "            'Combined Context': ' '.join(context),          \n",
    "            'Index': instance.index,               \n",
    "            'Sense Key': sense_key                  \n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "dev_df = create_dataframe(dev_instances, dev_key)\n",
    "test_df = create_dataframe(test_instances, test_key)\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_context(context):\n",
    "    processed_context = []\n",
    "    for word in context:\n",
    "        # Convert to lowercase\n",
    "        word = word.lower()\n",
    "\n",
    "        # Handle \"@card@\" tokens and numeric values by replacing with \"NUM\"\n",
    "        if word == \"@card@\" or re.fullmatch(r'\\d+', word):\n",
    "            processed_context.append(\"NUM\")\n",
    "            continue\n",
    "        \n",
    "        # Preserve periods within abbreviations and replace with underscores (e.g., \"u.n.\" -> \"u_n\")\n",
    "        word = re.sub(r'\\b(\\w\\.)+', lambda match: match.group(0).replace('.', '_'), word)\n",
    "        \n",
    "        # Split hyphenated compound words (e.g., \"u_n-sponsored\" -> [\"u_n\", \"sponsored\"])\n",
    "        parts = re.split(r'-(?=\\w)', word)\n",
    "        \n",
    "        # Process each part separately\n",
    "        for part in parts:\n",
    "            # Remove isolated punctuation from each part\n",
    "            part = part.strip(string.punctuation)\n",
    "            \n",
    "            # Lemmatize, remove stop words, and add to processed context if not empty\n",
    "            \n",
    "            # if part and part not in stop_words:\n",
    "            #     processed_context.append(lemmatizer.lemmatize(part))\n",
    "                \n",
    "            if part:\n",
    "                processed_context.append(lemmatizer.lemmatize(part))\n",
    "    \n",
    "    return processed_context\n",
    "\n",
    "# Example application\n",
    "dev_df['Modified Context'] = dev_df['Original Context'].apply(preprocess_context)\n",
    "test_df['Modified Context'] = test_df['Original Context'].apply(preprocess_context)\n",
    "\n",
    "dev_df['Combined Modified Context'] = dev_df['Modified Context'].apply(lambda x: ' '.join(x))\n",
    "test_df['Combined Modified Context'] = test_df['Modified Context'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "path_to_key = '/Users/aidanlicoppe/Documents/Code/keys'\n",
    "\n",
    "# Add the full file path of the directory containing api_keys.py\n",
    "sys.path.append(path_to_key)\n",
    "\n",
    "# Now import open_ai_key from api_keys.py\n",
    "from api_keys import google_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synset_codes(target_word):\n",
    "    \"\"\"\n",
    "    Retrieve the synset codes and definitions for the target word.\n",
    "    \"\"\"\n",
    "    synsets = wn.synsets(target_word)\n",
    "    synset_info = [(synset.name(), synset.definition()) for synset in synsets]\n",
    "    return synset_info\n",
    "\n",
    "def create_prompt_batches(sentences, lemmas, words_per_prompt=50):\n",
    "    # Words per prompt specifies the number of target lemmas per prompt\n",
    "    prompts = []\n",
    "    current_prompt = \"For each sentence below, choose the correct WordNet synset code for the target word in context.\\n\\n\"\n",
    "    \n",
    "    total_length = len(sentences)\n",
    "    lemmas_in_prompt = []\n",
    "\n",
    "    current_lemma_list = []\n",
    "    for i, (sentence, lemma) in enumerate(zip(sentences, lemmas)):\n",
    "        synset_info = get_synset_codes(lemma)\n",
    "        synset_descriptions = \"\\n\".join([f\"{code}: {definition}\" for code, definition in synset_info])\n",
    "        \n",
    "        current_entry = (\n",
    "            f\"Sentence {i + 1}: '{sentence}'\\n\"\n",
    "            f\"Target word: '{lemma}'\\n\"\n",
    "            f\"Synset Options:\\n{synset_descriptions}\\n\\n\"\n",
    "        )\n",
    "        \n",
    "        current_prompt += current_entry\n",
    "        current_lemma_list.append(lemma)\n",
    "        \n",
    "        if (i + 1) % words_per_prompt == 0 or i + 1 == total_length:\n",
    "            current_prompt += \"Please respond only with the synset code for each sentence, in order in the form of a comma-separated list, with no space between commas.\"\n",
    "            prompts.append(current_prompt)\n",
    "            \n",
    "            lemmas_in_prompt.append(current_lemma_list)\n",
    "            current_lemma_list = []\n",
    "            current_prompt = \"For each sentence below, choose the correct WordNet synset code for the target word in context.\\n\\n\"\n",
    "\n",
    "    return prompts, lemmas_in_prompt\n",
    "\n",
    "def estimate_tokens(prompt, tokenizer):\n",
    "    response = tokenizer.count_tokens(prompt)\n",
    "    num_tokens = response.total_tokens\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.preview.tokenization import get_tokenizer_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "tokenizer = get_tokenizer_for_model(\"gemini-1.5-flash-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_batch(sentences, lemmas):\n",
    "    prompt = \"For each sentence below, choose the correct WordNet synset code for the target word in context.\\n\\n\"\n",
    "    for i, (sentence, lemma) in enumerate(zip(sentences, lemmas)):\n",
    "        synset_info = get_synset_codes(lemma)\n",
    "        # Add each sentence, lemma, and synset options to the prompt\n",
    "        synset_descriptions = \"\\n\".join([f\"{code}: {definition}\" for code, definition in synset_info])\n",
    "        prompt += (\n",
    "            f\"Sentence {i + 1}: '{sentence}'\\n\"\n",
    "            f\"Target word: '{lemma}'\\n\"\n",
    "            f\"Synset Options:\\n{synset_descriptions}\\n\\n\"\n",
    "        )\n",
    "    prompt += \"Please respond only with the synset code for each sentence, in order in the form of a comma-separated list.\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = test_df['Combined Context']\n",
    "lemmas = test_df['Lemma']\n",
    "\n",
    "prompt = create_prompt_batch(sentences, lemmas)\n",
    "num_tokens = estimate_tokens(prompt, tokenizer)\n",
    "\n",
    "# Given that gemini allows up to 1 million tokens, we don't need to create batches and can include it all as a single prompt\n",
    "# For this, we will split up the prompts into chunks of lemmas such that the model can focus better\n",
    "\n",
    "\n",
    "def llm_WSD(sentences, lemmas, words_per_prompt=20, wait_time=5):\n",
    "    prompts, lemmas_in_prompt = create_prompt_batches(sentences, lemmas, words_per_prompt=words_per_prompt)\n",
    "    predictions = []\n",
    "    total_num_replacements = 0\n",
    "    \n",
    "    for j, prompt in enumerate(tqdm(prompts, desc=\"Processing Prompts\")):\n",
    "        response = model.generate_content(prompt)\n",
    "        text_response = response.text\n",
    "        cleaned_response = text_response.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "        response_list = cleaned_response.split(\",\")\n",
    "        \n",
    "        if len(response_list) != len(lemmas_in_prompt[j]):\n",
    "            # In the case where there is an error and no response is produced, we insert the most likely synset\n",
    "            for i in range(len(lemmas_in_prompt[j])):\n",
    "               possible_synsets_sets = get_synset_codes(lemmas_in_prompt[j][i])\n",
    "               possible_synsets = [code for code, definition in possible_synsets_sets]\n",
    "               if response_list[i] not in possible_synsets:\n",
    "                   response_list.insert(i, possible_synsets[0])\n",
    "                   total_num_replacements += 1\n",
    "        \n",
    "        predictions += response_list\n",
    "        \n",
    "        time.sleep(wait_time)\n",
    "    \n",
    "    return predictions, total_num_replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Prompts: 100%|██████████| 10/10 [00:38<00:00,  3.87s/it]\n"
     ]
    }
   ],
   "source": [
    "df = test_df\n",
    "\n",
    "sentences = df['Combined Context']\n",
    "lemmas = df['Lemma']\n",
    "\n",
    "predictions, num_replacements = llm_WSD(sentences, lemmas, words_per_prompt=50, wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_synsets = [wn.lemma_from_key(row['Sense Key'][0]).synset() for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predicted_synsets, actual_synsets, get_name=False):\n",
    "\n",
    "    correct_predictions = 0\n",
    "    correct_indices = []\n",
    "    incorrect_indices = []\n",
    "    \n",
    "    for i, (predicted, actual) in enumerate(zip(predicted_synsets, actual_synsets)):\n",
    "        if get_name:\n",
    "            actual = actual.name()\n",
    "        \n",
    "        if predicted == actual:\n",
    "            correct_predictions += 1\n",
    "            correct_indices.append(i)\n",
    "        else:\n",
    "            incorrect_indices.append(i)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / len(actual_synsets)\n",
    "    return accuracy, correct_indices, incorrect_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.10%\n"
     ]
    }
   ],
   "source": [
    "acc, correct_indices, incorrect_indices = calculate_accuracy(predictions, actual_synsets, get_name=True)\n",
    "\n",
    "print(\"--\" * 20)\n",
    "print(f\"Accuracy for WSD Using the Google Gemnini 1.5 Model: {acc*100:.2f}%\")\n",
    "print(\"--\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------- Correct Prediction Debug -----------------------------------------\n",
      "\n",
      "Instance ID: d001.s020.t005\n",
      "Prompt:\n",
      "For each sentence below, choose the correct WordNet synset code for the target word in context.\n",
      "\n",
      "Sentence 1: 'this be clearly a game where a new economic hegemony be be develop , say Ulate , who also serve as the regional Mexico and central_america climate_change adviser for conservation_international .'\n",
      "Target word: 'climate_change'\n",
      "Synset Options:\n",
      "climate_change.n.01: a change in the world's climate\n",
      "\n",
      "Please respond only with the synset code for each sentence, in order in the form of a comma-separated list.Please go through each of the available definitions, and justify why the word sense aligns with the definition or not. Finally, once you have gone through each definition, provide the correct synset of those available.\n",
      "\n",
      "Response:\n",
      "climate_change.n.01\n",
      "\n",
      "Justification:  The sentence discusses climate change in the context of a regional advisor for conservation.  climate_change.n.01, \"a change in the world's climate,\" accurately reflects this meaning. There are no other relevant WordNet synsets for \"climate_change\" that would fit this context.\n",
      "\n",
      "\n",
      "Actual Synset: Synset('climate_change.n.01')\n",
      "\n",
      "----------------------------------------- Incorrect Prediction Debug -----------------------------------------\n",
      "\n",
      "Instance ID: d001.s018.t005\n",
      "Prompt:\n",
      "For each sentence below, choose the correct WordNet synset code for the target word in context.\n",
      "\n",
      "Sentence 1: 'the current battle be as much about save individual economy as save the planet , with china and united_states feuding over their respective obligation while poor nation insist that the world 's two_dozen most influential country be ignore the scientific imperative to take bold action .'\n",
      "Target word: 'united_states'\n",
      "Synset Options:\n",
      "united_states.n.01: North American republic containing 50 states - 48 conterminous states in North America plus Alaska in northwest North America and the Hawaiian Islands in the Pacific Ocean; achieved independence in 1776\n",
      "united_states_government.n.01: the executive and legislative and judicial branches of the federal government of the United States\n",
      "\n",
      "Please respond only with the synset code for each sentence, in order in the form of a comma-separated list.Please go through each of the available definitions, and justify why the word sense aligns with the definition or not. Finally, once you have gone through each definition, provide the correct synset of those available.\n",
      "\n",
      "Response:\n",
      "united_states.n.01\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "* **united_states.n.01:** This synset refers to the country itself, its geography, and its historical context of independence.  This aligns perfectly with the sentence's use of \"United States\" as one of the major players in an international conflict.\n",
      "\n",
      "* **united_states_government.n.01:** This synset refers specifically to the governmental structure of the US. While the sentence discusses the US's actions, it does not focus on the internal workings of the government. The sentence refers to the country's role in a global dispute, not its governmental processes.\n",
      "\n",
      "Therefore, `united_states.n.01` is the correct synset.\n",
      "\n",
      "\n",
      "Actual Synset: Synset('united_states_government.n.01')\n"
     ]
    }
   ],
   "source": [
    "correct_samples = random.sample(correct_indices, 1) \n",
    "incorrect_samples = random.sample(incorrect_indices, 1)\n",
    "\n",
    "print(\"\\n----------------------------------------- Correct Prediction Debug -----------------------------------------\")\n",
    "for idx in correct_samples:\n",
    "    prompt_correct = create_prompt_batch([sentences[idx]], [lemmas[idx]])\n",
    "    prompt_correct = prompt_correct.replace(\"Please respond only with the synset code for each sentence, in order in the form of a comma-separated list, with no space between commas.\", \"\")\n",
    "    prompt_correct += 'Please go through each of the available definitions, and justify why the word sense aligns with the definition or not. Finally, once you have gone through each definition, provide the correct synset of those available.'\n",
    "    response_correct = model.generate_content(prompt_correct)\n",
    "    \n",
    "    print(f\"\\nInstance ID: {df.iloc[idx]['Instance ID']}\")\n",
    "    print(f\"Prompt:\\n{prompt_correct}\")\n",
    "    print(f\"\\nResponse:\\n{response_correct.text}\")\n",
    "    print(f\"\\nActual Synset: {actual_synsets[idx]}\")\n",
    "\n",
    "print(\"\\n----------------------------------------- Incorrect Prediction Debug -----------------------------------------\")\n",
    "for idx in incorrect_samples:\n",
    "    prompt_incorrect = create_prompt_batch([sentences[idx]], [lemmas[idx]])\n",
    "    prompt_incorrect = prompt_incorrect.replace(\"Please respond only with the synset code for each sentence, in order in the form of a comma-separated list, with no space between commas.\", \"\")\n",
    "    prompt_incorrect += 'Please go through each of the available definitions, and justify why the word sense aligns with the definition or not. Finally, once you have gone through each definition, provide the correct synset of those available.'\n",
    "    \n",
    "    response_incorrect = model.generate_content(prompt_incorrect)\n",
    "    \n",
    "    print(f\"\\nInstance ID: {df.iloc[idx]['Instance ID']}\")\n",
    "    print(f\"Prompt:\\n{prompt_incorrect}\")\n",
    "    print(f\"\\nResponse:\\n{response_incorrect.text}\")\n",
    "    print(f\"\\nActual Synset: {actual_synsets[idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
